{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "# Batch dispersion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Initialise session and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration file from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/src/config.yaml\n",
      "\u001b[32mLoaded configuration file\u001b[0m\n",
      "Loading devices data file from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/interim\n",
      "\u001b[32mData initialisation done\u001b[0m\n",
      "Loading deliveries file from: /Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/interim/deliveries/deliveries.yaml\n"
     ]
    }
   ],
   "source": [
    "import warnings                                  \n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.colors\n",
    "from os.path import join\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from src.data.data import *\n",
    "data = data_wrapper()\n",
    "\n",
    "deliveries_path = join(data.interimDirectory, 'deliveries', 'deliveries.yaml')\n",
    "with open(deliveries_path, 'r') as deliveries_yaml:\n",
    "    print (f'Loading deliveries file from: {deliveries_path}')\n",
    "    deliveries = yaml.load(deliveries_yaml, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'completed': False,\n",
      "    'date': '2020-01-22',\n",
      "    'enclosure': 'hdpe',\n",
      "    'extras': None,\n",
      "    'file': 'ISGLOBAL/4.csv',\n",
      "    'power_supply': 'solar',\n",
      "    'report': None,\n",
      "    'sensors_delivered': 53,\n",
      "    'sensors_tested': 55}\n"
     ]
    }
   ],
   "source": [
    "# INPUT DATA\n",
    "# Name of test to be analysed\n",
    "delivery = 'ISGLOBAL'\n",
    "batch = 4\n",
    "type_file = None\n",
    "# Percentage of points to be considered NG sensor\n",
    "limit_errors = 3\n",
    "# Multiplier for std_dev (sigma) - Normal distribution (99.73%)\n",
    "limit_confidence_sigma = 3\n",
    "# t-student confidence level (%)\n",
    "t_confidence_level = 99\n",
    "# Use average dispersion or instantaneous\n",
    "use_instantatenous_dispersion = False\n",
    "# Min/max date for the analysis\n",
    "# min_date = '2019-12-10 18:00:00'\n",
    "min_date = None\n",
    "max_date = None\n",
    "# In case there is a device with lower amount of channels, ignore the missing channels and keep going\n",
    "ignore_missing_channels = True\n",
    "# Smooth channels\n",
    "smooth_channels = True\n",
    "smooth_number = 5\n",
    "## Info of this delivery\n",
    "pp.pprint (deliveries[delivery]['batches'][batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data.load_test(dispersion_test, options = {'clean_na': True, 'clean_na_method': 'drop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print (data.tests['2019-12_INT_ISGLOBAL_22_KITS_RECALL'].devices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "## Get list of common channels\n",
    "Displays a warning in case there is a device that has fewer channels than the rest. You can choose whether or not to ignore it or update the list of common channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Get list of common channels\n",
    "save_path = join(data.dataDirectory, 'export/figs', dispersion_test)\n",
    "# Test Path\n",
    "if not exists(save_path):\n",
    "    print ('Creating export directory:\\n{}'.format(save_path))\n",
    "    mkdir(save_path)\n",
    "\n",
    "list_channels = list()\n",
    "# Get list of devices\n",
    "list_devices = list(data.tests[dispersion_test].devices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Init list of common channels. Get the one that has the most\n",
    "list_channels = data.tests[dispersion_test].devices[list_devices[0]].readings.columns\n",
    "# Extract list of common channels\n",
    "len_channels = len(list_channels)\n",
    "\n",
    "for device in list_devices:\n",
    "    \n",
    "    if ignore_missing_channels: \n",
    "        # We don't reduce the list in case the new list is smaller\n",
    "        list_channels = list(set(list_channels) | set(data.tests[dispersion_test].devices[device].readings.columns))\n",
    "    else:\n",
    "        # We reduce it\n",
    "        list_channels = list(set(list_channels) & set(data.tests[dispersion_test].devices[device].readings.columns))\n",
    "\n",
    "    print ('Device {}'.format(device))\n",
    "    print ('\\tMin reading at {}'.format(data.tests[dispersion_test].devices[device].readings.index[0]))\n",
    "    #min_date_records = min(min_date_records, records.readings[dispersion_test]['devices'][device]['data'].index[0])\n",
    "    print ('\\tMax reading at {}'.format(data.tests[dispersion_test].devices[device].readings.index[-1]))\n",
    "    #max_date_records = min(max_date_records, records.readings[dispersion_test]['devices'][device]['data'].index[-1])\n",
    "    print ('\\tNumber of points {}'.format(len(data.tests[dispersion_test].devices[device].readings.index)))\n",
    "    ## Eliminate devices with no points\n",
    "    if (len(data.tests[dispersion_test].devices[device].readings.index) == 0):\n",
    "        print ('Droping device {} for insufficient data points'.format(device))\n",
    "        data.tests[dispersion_test].devices.pop(device)\n",
    "    # Check the number of channels    \n",
    "    elif len_channels != len(data.tests[dispersion_test].devices[device].readings.columns): \n",
    "        print(\"\\tWARNING: Device {} has {}. Current common list length is {}\".format(device, len(data.tests[dispersion_test].devices[device].readings.columns), len_channels))\n",
    "        len_channels = len(list_channels)\n",
    "        if ignore_missing_channels:\n",
    "            print (\"\\tIgnoring missing channels\")\n",
    "\n",
    "print('Final list of channels:\\n', list_channels)\n",
    "\n",
    "if min_date is not None: min_date = pd.to_datetime(min_date).tz_localize('UTC').tz_convert('Europe/Madrid')\n",
    "if max_date is not None: max_date = pd.to_datetime(max_date).tz_localize('UTC').tz_convert('Europe/Madrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<p><strong>Test name:</strong><br> {}</p>'.format(dispersion_test)))\n",
    "display(HTML('<p><strong>Total number of devices tested:</strong><br> {}</p>'.format(len(list_devices))))\n",
    "display(HTML('<p><strong>Test dates:</strong><br> {} - {}</p>'.format(min_date, max_date)))\n",
    "display(HTML('<p><strong>Test author(s):</strong><br> {}</p><hr>'.format('√ìscar Gonz√°lez - Victor Barber√°n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "### Test Explanation\n",
    "\n",
    "The devices are co-located for a period of at least 3 days in an **indoor** environment. Devices that show an abnormal behaviour are analysed and replaced if necessary. **In this case, the devices were tested for 2+ weeks during Christmas holidays**.\n",
    "\n",
    "#### Comment on methods\n",
    "- This analysis is conditioned to the low amount of devices tested. The plots below indicate only trends and highlight some (but not all) potential faulty devices.\n",
    "- Below, the confidence intervals used are those of the normal distribution (sample numbers >30) and of the t-student distribution (sample numbers <30).\n",
    "The testing of the devices is done for at least 3-5 days. If any problem is seen, longer periods are tested if needed. Also note that statistical significance cannot be inferred from these amounts of devices, and some assumptions have to be accepted. Comments and further discussion are always welcome.\n",
    "- The individual sensors components integrated in the Smart Citizen hardware have their own accuracies and dispersions, for which Smart Citizen cannot assume any liability other than trying to work with the most appropiate selection. The tests we perform are aimed to determine and assume any failures in the sensors and their integration within the Smart Citizen hardware. For more information, please check the <a href=\"https://docs.smartcitizen.me\">official documentation</a> and the datasheets of each of the sensors in the [sensors part](https://docs.smartcitizen.me/Components/Urban%20Sensor%20Board/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "# Calculate the dispersion for the sensors present in the dataset\n",
    "dispersion_df = pd.DataFrame()\n",
    "dispersion_history = list()\n",
    "display(HTML('<h3>Warnings</h3>'))\n",
    "warning_displayed = False\n",
    "location = None\n",
    "\n",
    "for device in list_devices:\n",
    "    location_test = data.tests[dispersion_test].devices[device].location\n",
    "    if location_test is None: data.std_out (f'Device {device} has no location')\n",
    "    else:\n",
    "        if location is None: location = location_test\n",
    "        elif location_test != location: data.std_out (f'Device {device} has different location!')\n",
    "        \n",
    "for channel in list_channels:\n",
    "    list_columns = list()\n",
    "    if channel != 'BATT':\n",
    "        for device in list_devices:\n",
    "            if channel in data.tests[dispersion_test].devices[device].readings.columns and len(data.tests[dispersion_test].devices[device].readings.loc[:,channel]) >0 :\n",
    "                # Important to resample and bfill for unmatching measures\n",
    "                if smooth_channels:\n",
    "                    channel_new = data.tests[dispersion_test].devices[device].readings[channel].resample('1Min').bfill().rolling(window=smooth_number).mean()\n",
    "                    dispersion_df[channel + '-' + device] = channel_new[channel_new > 0]\n",
    "                else:\n",
    "                    dispersion_df[channel + '-' + device] = data.tests[dispersion_test].devices[device].readings[channel].resample('1Min').bfill()\n",
    "                \n",
    "                list_columns.append(channel + '-' + device)\n",
    "            else:\n",
    "                display(HTML('<p>WARNING: Device {} does not contain {}</p>'.format(device, channel)))\n",
    "                warning_displayed = True\n",
    "    try:\n",
    "        if dispersion_df.index.tzinfo is None: dispersion_df.index = dispersion_df.index.tz_localize('UTC').tz_convert(location)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    \n",
    "    # Trim dataset to min and max dates (normally these tests are carried out with _minutes_ of differences)\n",
    "    if min_date is not None: dispersion_df = dispersion_df[dispersion_df.index > min_date]\n",
    "    if max_date is not None: dispersion_df = dispersion_df[dispersion_df.index < max_date]\n",
    "\n",
    "    # Calculate Metrics\n",
    "    dispersion_df[channel + '_AVG'] = dispersion_df.loc[:,list_columns].mean(skipna=True, axis = 1)\n",
    "    dispersion_df[channel + '_STD'] = dispersion_df.loc[:,list_columns].std(skipna=True, axis = 1)\n",
    " \n",
    "    # Calculate Metrics\n",
    "    dispersion_global = dispersion_df[channel + '_STD'].mean()\n",
    "    # print (dispersion_df.index[0], dispersion_df.index[-1], channel, dispersion_global)\n",
    "    dispersion_history.append([channel, dispersion_global])\n",
    "if not warning_displayed:\n",
    "    display(HTML('<p>All devices show similar amounts of data. No data loss concern</p>'.format(device, channel)))\n",
    "    \n",
    "# display(HTML('<h3>Sensor dispersion</h3>'))\n",
    "# display(HTML('<p>Below, the sensor dispersion for each channel is listed (units of each sensor)</p>'))\n",
    "# dispersion_history = tuple(dispersion_history)\n",
    "# display(HTML('<ul style=\"list-style-type:disc;\">'))\n",
    "# for item in dispersion_history:\n",
    "#     display(HTML('<li>{}: {}</li>'.format(item[0], item[1])))\n",
    "# display(HTML('</ul>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<hr>'))\n",
    "display(HTML('<div class=\"pagebreak\"> </div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Internal notes:\n",
    "    \n",
    "+ iSCAPE:\n",
    "    - 10408: pm sensor ??\n",
    "    - 10413: pm sensor A\n",
    "    - 10420: pm sensor A \n",
    "    - 10409: pm sensor B\n",
    "     \n",
    "    - Sensor resetting issue:\n",
    "        1. 10422 1 PM Disconnected (11-11 19h)\n",
    "        2. 10421 Gases Pro Board Disconnected (11-11 19h)\n",
    "        3. Added battery to 9994 (12-11 13h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "## Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "- 4E77: Wasn't publishing - 10621: no battery (not connected to power supply) --> üëçüèΩ\n",
    "- 2EC0: Hasn't published PM - 10619: PM sensor was disconnected --> üëçüèΩ\n",
    "- FD94: Only published battery -  10615. Shows signs of water corrosion - Replaced full kit by a new one (not PM sensor) --> üëçüèΩ\n",
    "\n",
    "<div style=\"text-align: left\" >\n",
    "<img src=\"https://i.imgur.com/crIy7Cz.jpg\" width=500px>\n",
    "</div>\n",
    "\n",
    "- 7FCB: Wasn't publishing - 10607: no battery (got disconnected by accident from power supply). The CCS811 was damaged (see below). After replacement of urban board. Full period shows good behaviour. --> üëçüèΩ\n",
    "\n",
    "<div style=\"text-align: left\" >\n",
    "<img src=\"https://i.imgur.com/s3IeuyB.jpg\" width=500px>\n",
    "</div>\n",
    "\n",
    "- All eCO2/tVOC sensors show high dispersion values in _two or more_ distinct behaviours. After 8/01/2020 they start converging, but they still show high dispersion. No action is taken, unless is requested to. This shows that, probably, if the sensors were set in different environments, their behaviour with respect to the baseline takes longer than the manufacturer says to stabilise.\n",
    "- All PM sensors show good behaviour\n",
    "- Three sensors show warnings in humidity: two of them are due to no publication. One of them shows higher dispersion with ~5%rh. No action is taken as the value somewhat near the +-2%rh typical accuracy of the sensor, accounting for the possible test bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<hr>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "source": [
    "## Time Series Plot (Full Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list_channels_kit =  ['PRESS', 'CCS811_ECO2', 'EXT_PM_10', 'NOISE_A', 'TEMP', 'CCS811_VOCS', 'HUM', 'EXT_PM_1', 'LIGHT', 'EXT_PM_25']\n",
    "test_for_kit = False\n",
    "list_channels_plots = list_channels_kit if test_for_kit else list_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h2>Time Series Plots</h2>'))\n",
    "min_date = '2019-12-15'\n",
    "if min_date is None: min_date_test = dispersion_df.index[-1] \n",
    "else: min_date_test = min_date\n",
    "if max_date is None: max_date_test = dispersion_df.index[-1] \n",
    "else: max_date_test = max_date\n",
    "display(HTML('Min Date available: {}'.format(min_date_test)))\n",
    "display(HTML('Max Date available: {}'.format(max_date_test)))\n",
    "\n",
    "dispersion_df_trim = dispersion_df.copy()\n",
    "dispersion_df_trim = dispersion_df_trim[dispersion_df_trim.index > min_date_test]\n",
    "dispersion_df_trim = dispersion_df_trim[dispersion_df_trim.index < max_date_test]\n",
    "\n",
    "# Ignore battery\n",
    "if 'BATT' in list_channels_plots: list_channels_plots.remove('BATT')\n",
    "dict_devices_tbr = dict()\n",
    "for item in list_channels_plots: dict_devices_tbr[item] = list()\n",
    "\n",
    "for channel in list_channels_plots:\n",
    "    if channel not in list_channels_plots and test_for_kit: continue\n",
    "    # Make subplot\n",
    "    list_columns = list()\n",
    "    fig, (ax1, ax2) = plot.subplots(nrows = 2, figsize= (15,10))\n",
    "    cmap = plot.cm.Reds\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=limit_errors/2)\n",
    "    index = list_channels_plots.index(channel)+1\n",
    "    total_number = len(list_channels_plots)\n",
    "    display(HTML('<h3>({}/{}) - {} </h3>'.format(index, total_number, channel)))\n",
    "    \n",
    "    dispersion_avg = 0\n",
    "    limit_confidence_sigma = 0\n",
    "    for item in dispersion_history:\n",
    "        if channel == item[0]:\n",
    "            dispersion_avg = item[1]\n",
    "            \n",
    "    if len(list_devices)>30:\n",
    "        display(HTML('<p>Using Normal Distribution. Using limit for sigma confidence: {}'.format(limit_confidence_sigma)))\n",
    "        limit_confidence = limit_confidence_sigma\n",
    "        # Calculate upper and lower bounds\n",
    "        if (use_instantatenous_dispersion):\n",
    "            # For sensors with high variability in the measurements, it's better to use this (i.e. alphasense)\n",
    "            upper_bound = dispersion_df_trim[channel + '_AVG'] + limit_confidence * dispersion_df_trim[channel + '_STD']\n",
    "            lower_bound = dispersion_df_trim[channel + '_AVG'] - abs(limit_confidence * dispersion_df_trim[channel + '_STD'])\n",
    "        else:\n",
    "            upper_bound = dispersion_df_trim[channel + '_AVG'] + limit_confidence * dispersion_avg\n",
    "            lower_bound = dispersion_df_trim[channel + '_AVG'] - abs(limit_confidence * dispersion_avg)\n",
    "    else:\n",
    "        limit_confidence = t.interval(t_confidence_level/100.0, len(list_devices), loc=dispersion_df_trim[channel + '_AVG'], scale=dispersion_avg)\n",
    "        display(HTML('<p>Using t-student Distribution</p>'))\n",
    "        upper_bound = limit_confidence[1]\n",
    "        lower_bound = limit_confidence[0]\n",
    "\n",
    "    dispersion_df_trim[channel + '_MAX'] = dispersion_df_trim.loc[:,list_columns].max(skipna=True, axis = 1)\n",
    "    dispersion_df_trim[channel + '_MIN'] = dispersion_df_trim.loc[:,list_columns].min(skipna=True, axis = 1)\n",
    "        \n",
    "    # print ('Plotting devices')\n",
    "    for device in list_devices:\n",
    "        name_column = channel + '-' + device \n",
    "        if name_column in dispersion_df_trim.columns:\n",
    "            # Count how many times we go above the upper bound or below the lower one\n",
    "            count_problems_up = dispersion_df_trim[name_column] > upper_bound\n",
    "            count_problems_down =  dispersion_df_trim[name_column] < lower_bound\n",
    "            \n",
    "            # Count them\n",
    "            count_problems = [1 if (count_problems_up[i] or count_problems_down[i]) else 0 for i in range(len(count_problems_up))]\n",
    "            # print (channel, device, np.sum(count_problems), len(count_problems))\n",
    "            \n",
    "            # Add the trace in either\n",
    "            number_errors = np.sum(count_problems)\n",
    "            max_number_errors = len(count_problems)\n",
    "            \n",
    "            if number_errors/max_number_errors > limit_errors/100:\n",
    "                print (f'WARNING: Device {device} out of {limit_errors}% limit - {np.round(number_errors/max_number_errors*100, 1)}% out')\n",
    "                if device not in dict_devices_tbr[channel]: dict_devices_tbr[channel].append(device)\n",
    "                alpha = 1\n",
    "                ax1.plot(dispersion_df_trim.index, \n",
    "                         dispersion_df_trim[name_column], \n",
    "                         color = 'r',\n",
    "                         label = device, alpha = alpha)\n",
    "            else:\n",
    "                alpha = 1\n",
    "                color = 'g'\n",
    "                ax2.plot(dispersion_df_trim.index, \n",
    "                         dispersion_df_trim[name_column], \n",
    "                         color = color, \n",
    "                         label = device, alpha = alpha)\n",
    "        \n",
    "    # Add upper and low bound bound to subplot 1\n",
    "    ax1.plot(dispersion_df_trim.index, dispersion_df_trim[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df_trim.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df_trim.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    lgd1 = ax1.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_ylabel(channel + ' TBR')\n",
    "    ax1.set_xlabel('Time')\n",
    "    \n",
    "    # Add upper and low bound bound to subplot 2\n",
    "    ax2.plot(dispersion_df_trim.index, dispersion_df_trim[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df_trim.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df_trim.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    lgd2 = ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylabel(channel + ' OK')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "    # Check file type to make the export\n",
    "    if type_file is not None: print ('Saving figure')\n",
    "    if type_file == 'fig':\n",
    "        pickle.dump(fig, open(save_path + '/' + dispersion_test + '_' + channel + '.fig.pickle', 'wb'))\n",
    "    elif type_file == 'png':\n",
    "        fig.savefig(save_path + '/' + dispersion_test + '_' + channel + '.png', dpi=300, trasnparent = True, bbox_extra_artists=(lgd1, lgd2), bbox_inches='tight' )\n",
    "\n",
    "    # Show plots     \n",
    "    plot.show()\n",
    "    display(HTML('<br>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(index = list_channels_plots)\n",
    "\n",
    "for item in dispersion_history:\n",
    "    summary_df.loc[item[0], 'Dispersion'] = item[1]\n",
    "    if item[0] != 'BATT':\n",
    "        summary_df.loc[item[0], 'Total Number of devices'] = len(list_devices)\n",
    "        summary_df.loc[item[0], 'TBR Number of devices'] = len(dict_devices_tbr[item[0]])\n",
    "        summary_df.loc[item[0], 'OK Number of devices'] = len(list_devices) - len(dict_devices_tbr[item[0]])\n",
    "    \n",
    "display (summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Time Series Plot (After fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "show_only_output"
    ]
   },
   "outputs": [],
   "source": [
    "display(HTML('<h2>Time Series Plots</h2>'))\n",
    "min_date = '2020-01-08'\n",
    "if min_date is None: min_date_test = dispersion_df.index[-1] \n",
    "else: min_date_test = min_date\n",
    "if max_date is None: max_date_test = dispersion_df.index[-1] \n",
    "else: max_date_test = max_date\n",
    "display(HTML('Min Date available: {}'.format(min_date_test)))\n",
    "display(HTML('Max Date available: {}'.format(max_date_test)))\n",
    "\n",
    "dispersion_df_trim = dispersion_df.copy()\n",
    "dispersion_df_trim = dispersion_df_trim[dispersion_df_trim.index > min_date_test]\n",
    "dispersion_df_trim = dispersion_df_trim[dispersion_df_trim.index < max_date_test]\n",
    "\n",
    "# Ignore battery\n",
    "if 'BATT' in list_channels_plots: list_channels_plots.remove('BATT')\n",
    "dict_devices_tbr = dict()\n",
    "for item in list_channels_plots: dict_devices_tbr[item] = list()\n",
    "\n",
    "for channel in list_channels_plots:\n",
    "    if channel not in list_channels_plots and test_for_kit: continue\n",
    "    # Make subplot\n",
    "    list_columns = list()\n",
    "    fig, (ax1, ax2) = plot.subplots(nrows = 2, figsize= (15,10))\n",
    "    cmap = plot.cm.Reds\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=limit_errors/2)\n",
    "    index = list_channels_plots.index(channel)+1\n",
    "    total_number = len(list_channels_plots)\n",
    "    display(HTML('<h3>({}/{}) - {} </h3>'.format(index, total_number, channel)))\n",
    "    \n",
    "    dispersion_avg = 0\n",
    "    limit_confidence_sigma = 0\n",
    "    for item in dispersion_history:\n",
    "        if channel == item[0]:\n",
    "            dispersion_avg = item[1]\n",
    "            \n",
    "    if len(list_devices)>30:\n",
    "        display(HTML('<p>Using Normal Distribution. Using limit for sigma confidence: {}'.format(limit_confidence_sigma)))\n",
    "        limit_confidence = limit_confidence_sigma\n",
    "        # Calculate upper and lower bounds\n",
    "        if (use_instantatenous_dispersion):\n",
    "            # For sensors with high variability in the measurements, it's better to use this (i.e. alphasense)\n",
    "            upper_bound = dispersion_df_trim[channel + '_AVG'] + limit_confidence * dispersion_df_trim[channel + '_STD']\n",
    "            lower_bound = dispersion_df_trim[channel + '_AVG'] - abs(limit_confidence * dispersion_df_trim[channel + '_STD'])\n",
    "        else:\n",
    "            upper_bound = dispersion_df_trim[channel + '_AVG'] + limit_confidence * dispersion_avg\n",
    "            lower_bound = dispersion_df_trim[channel + '_AVG'] - abs(limit_confidence * dispersion_avg)\n",
    "    else:\n",
    "        limit_confidence = t.interval(t_confidence_level/100.0, len(list_devices), loc=dispersion_df_trim[channel + '_AVG'], scale=dispersion_avg)\n",
    "        display(HTML('<p>Using t-student Distribution</p>'))\n",
    "        upper_bound = limit_confidence[1]\n",
    "        lower_bound = limit_confidence[0]\n",
    "\n",
    "    dispersion_df_trim[channel + '_MAX'] = dispersion_df_trim.loc[:,list_columns].max(skipna=True, axis = 1)\n",
    "    dispersion_df_trim[channel + '_MIN'] = dispersion_df_trim.loc[:,list_columns].min(skipna=True, axis = 1)\n",
    "        \n",
    "    # print ('Plotting devices')\n",
    "    for device in list_devices:\n",
    "        name_column = channel + '-' + device \n",
    "        if name_column in dispersion_df_trim.columns:\n",
    "            # Count how many times we go above the upper bound or below the lower one\n",
    "            count_problems_up = dispersion_df_trim[name_column] > upper_bound\n",
    "            count_problems_down =  dispersion_df_trim[name_column] < lower_bound\n",
    "            \n",
    "            # Count them\n",
    "            count_problems = [1 if (count_problems_up[i] or count_problems_down[i]) else 0 for i in range(len(count_problems_up))]\n",
    "            # print (channel, device, np.sum(count_problems), len(count_problems))\n",
    "            \n",
    "            # Add the trace in either\n",
    "            number_errors = np.sum(count_problems)\n",
    "            max_number_errors = len(count_problems)\n",
    "            \n",
    "            if number_errors/max_number_errors > limit_errors/100:\n",
    "                print (f'WARNING: Device {device} out of {limit_errors}% limit - {np.round(number_errors/max_number_errors*100, 1)}% out')\n",
    "                if device not in dict_devices_tbr[channel]: dict_devices_tbr[channel].append(device)\n",
    "                alpha = 1\n",
    "                ax1.plot(dispersion_df_trim.index, \n",
    "                         dispersion_df_trim[name_column], \n",
    "                         color = 'r',\n",
    "                         label = device, alpha = alpha)\n",
    "            else:\n",
    "                alpha = 1\n",
    "                color = 'g'\n",
    "                ax2.plot(dispersion_df_trim.index, \n",
    "                         dispersion_df_trim[name_column], \n",
    "                         color = color, \n",
    "                         label = device, alpha = alpha)\n",
    "        \n",
    "    # Add upper and low bound bound to subplot 1\n",
    "    ax1.plot(dispersion_df_trim.index, dispersion_df_trim[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df_trim.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax1.plot(dispersion_df_trim.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    lgd1 = ax1.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_ylabel(channel + ' TBR')\n",
    "    ax1.set_xlabel('Time')\n",
    "    \n",
    "    # Add upper and low bound bound to subplot 2\n",
    "    ax2.plot(dispersion_df_trim.index, dispersion_df_trim[channel + '_AVG'],'b', label = 'Average', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df_trim.index, upper_bound, 'k', label = 'Upper-Bound', alpha = 0.6)\n",
    "    ax2.plot(dispersion_df_trim.index, lower_bound, 'k',label = 'Lower-Bound', alpha = 0.6)\n",
    "    \n",
    "    # Format the legend\n",
    "    ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    lgd2 = ax2.legend(bbox_to_anchor=(1.1, 0.5), fancybox=True, loc='center left', ncol = 5)\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylabel(channel + ' OK')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "    # Check file type to make the export\n",
    "    if type_file is not None: print ('Saving figure')\n",
    "    if type_file == 'fig':\n",
    "        pickle.dump(fig, open(save_path + '/' + dispersion_test + '_' + channel + '.fig.pickle', 'wb'))\n",
    "    elif type_file == 'png':\n",
    "        fig.savefig(save_path + '/' + dispersion_test + '_' + channel + '.png', dpi=300, trasnparent = True, bbox_extra_artists=(lgd1, lgd2), bbox_inches='tight' )\n",
    "\n",
    "    # Show plots     \n",
    "    plot.show()\n",
    "    display(HTML('<br>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
